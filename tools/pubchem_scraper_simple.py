"""
PubChemæ•°æ®é‡‡é›†å·¥å…· - ç®€åŒ–ç‰ˆ
ä½¿ç”¨å·²çŸ¥åŒ–åˆç‰©CIDåˆ—è¡¨ç›´æ¥é‡‡é›†ï¼Œæ›´å¯é ã€æ›´å¿«é€Ÿ
"""

import os
import sys
import time
import json
import logging
import re
from pathlib import Path
from typing import List, Dict, Optional, Set
from datetime import datetime

import requests
import pandas as pd
from tqdm import tqdm
from rdkit import Chem

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SimplePubChemScraper:
    """ç®€åŒ–ç‰ˆPubChemé‡‡é›†å™¨ - ä½¿ç”¨å·²çŸ¥CIDåˆ—è¡¨"""
    
    def __init__(self, output_dir: str = "data/raw"):
        self.base_url = "https://pubchem.ncbi.nlm.nih.gov/rest/pug"
        self.output_dir = Path(PROJECT_ROOT) / output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.output_file = self.output_dir / "pubchem_compounds.csv"
        self.requests_per_second = 5
        self.last_request_time = 0
        
        # å·²çŸ¥çš„å«pKaæ•°æ®çš„åŒ–åˆç‰©CIDï¼ˆæ‰©å±•åˆ—è¡¨ï¼‰
        self.known_pka_cids = self._build_cid_list()
        
        logger.info(f"åˆå§‹åŒ–å®Œæˆï¼Œå·²åŠ è½½ {len(self.known_pka_cids)} ä¸ªå·²çŸ¥åŒ–åˆç‰©CID")
    
    def _build_cid_list(self) -> List[int]:
        """æ„å»ºå·²çŸ¥å«pKaæ•°æ®çš„åŒ–åˆç‰©CIDåˆ—è¡¨"""
        cids = []
        
        # 1. ç¾§é…¸ç±» (pKa ~2-5)
        carboxylic_acids = [
            176,      # ä¹™é…¸ pKa 4.76
            264,      # ç”²é…¸ pKa 3.75
            338,      # ä¸™é…¸ pKa 4.87
            1031,     # ä¸é…¸ pKa 4.82
            7991,     # æˆŠé…¸ pKa 4.83
            8892,     # å·±é…¸ pKa 4.85
            243,      # è‹¯ç”²é…¸ pKa 4.20
            445858,   # æ°´æ¨é…¸ pKa 2.97
            1060,     # é‚»è‹¯äºŒç”²é…¸ pKa 2.89
            10313,    # è‰é…¸ pKa 1.25
            311,      # ç¥ç€é…¸ pKa 4.21
            1110,     # é©¬æ¥é…¸ pKa 1.92
            444972,   # å¯Œé©¬é…¸ pKa 3.03
        ]
        cids.extend(carboxylic_acids)
        
        # 2. é…šç±» (pKa ~8-11)
        phenols = [
            996,      # è‹¯é…š pKa 9.95
            135,      # å¯¹ç”²é…š pKa 10.26
            7150,     # é—´ç”²é…š pKa 10.09
            2879,     # é‚»ç”²é…š pKa 10.28
            7342,     # å¯¹ç¡åŸºè‹¯é…š pKa 7.15
            2394,     # é—´ç¡åŸºè‹¯é…š pKa 8.35
            1970,     # é‚»ç¡åŸºè‹¯é…š pKa 7.23
            6998,     # å„¿èŒ¶é…š pKa 9.34
            289,      # æ°¢é†Œ pKa 9.85
            7054,     # å¯¹æ°¨åŸºè‹¯é…š pKa 10.30
        ]
        cids.extend(phenols)
        
        # 3. èƒºç±» (pKa ~9-11)
        amines = [
            6267,     # ä¹™èƒº pKa 10.7
            6537,     # äºŒä¹™èƒº pKa 10.9
            6115,     # è‹¯èƒº pKa 4.6
            7515,     # ç”²èƒº pKa 10.6
            9270,     # æ­£ä¸™èƒº pKa 10.5
            7712,     # å¡å•¶ pKa 5.2
            1049,     # å¡å•¶ pKa 5.25
            8082,     # å’ªå”‘ pKa 6.95
            795,      # å’ªå”‘ pKa 7.0
            8248,     # å“Œå•¶ pKa 11.1
            8252,     # å—å•‰ pKa 8.5
        ]
        cids.extend(amines)
        
        # 4. æ°¨åŸºé…¸ç±» (pKa ~2-10)
        amino_acids = [
            5950,     # L-ä¸™æ°¨é…¸ pKa 2.34, 9.69
            6137,     # ç”˜æ°¨é…¸ pKa 2.34, 9.60
            6287,     # L-ç¼¬æ°¨é…¸ pKa 2.32, 9.62
            6306,     # L-äº®æ°¨é…¸ pKa 2.36, 9.60
            6322,     # L-å¼‚äº®æ°¨é…¸ pKa 2.36, 9.68
            6274,     # L-è‹¯ä¸™æ°¨é…¸ pKa 1.83, 9.13
            6305,     # L-è‰²æ°¨é…¸ pKa 2.38, 9.39
            6288,     # L-è›‹æ°¨é…¸ pKa 2.28, 9.21
            5960,     # L-è„¯æ°¨é…¸ pKa 1.99, 10.60
            750,      # L-è°·æ°¨é…¸ pKa 2.19, 4.25, 9.67
            5961,     # L-å¤©å†¬æ°¨é…¸ pKa 1.88, 3.65, 9.60
            6106,     # L-èµ–æ°¨é…¸ pKa 2.18, 8.95, 10.53
            6140,     # L-ç²¾æ°¨é…¸ pKa 2.17, 9.04, 12.48
        ]
        cids.extend(amino_acids)
        
        # 5. è¯ç‰©åˆ†å­
        drugs = [
            2244,     # é˜¿å¸åŒ¹æ— pKa 3.5
            3672,     # å¸ƒæ´›èŠ¬ pKa 4.91
            60823,    # è˜æ™®ç”Ÿ pKa 4.15
            2519,     # å’–å•¡å›  pKa 10.4
            3825,     # å°¼å¤ä¸ pKa 8.0
            4409,     # å—å•¡ pKa 8.0
            2585,     # å¯å¾…å›  pKa 8.2
            3345,     # æ‰‘çƒ­æ¯ç—› pKa 9.5
            4754,     # è‹¯å·´æ¯”å¦¥ pKa 7.4
            2157,     # æ°´æ¨é…¸é’  pKa 2.97
        ]
        cids.extend(drugs)
        
        # 6. æ‚ç¯åŒ–åˆç‰©
        heterocycles = [
            1174,     # å¡å’¯ pKa 17.5
            9253,     # å²å“š pKa 16.97
            1140,     # å‘‹å–ƒ
            8030,     # å™»å©
            1049,     # å¡å•¶ pKa 5.25
            9246,     # å–¹å•‰ pKa 4.9
            8580,     # å¼‚å–¹å•‰ pKa 5.4
        ]
        cids.extend(heterocycles)
        
        # 7. å…¶ä»–é‡è¦åŒ–åˆç‰©
        others = [
            962,      # æ°´ pKa 15.7
            1118,     # ç¡«é…¸ pKa -3
            313,      # ç£·é…¸ pKa 2.15
            1032,     # ç¢³é…¸ pKa 6.35
            284,      # æ°¨ pKa 9.25
            1031,     # ç¡¼é…¸ pKa 9.24
        ]
        cids.extend(others)
        
        return list(set(cids))  # å»é‡
    
    def _rate_limit(self):
        """é€Ÿç‡é™åˆ¶"""
        min_interval = 1.0 / self.requests_per_second
        elapsed = time.time() - self.last_request_time
        if elapsed < min_interval:
            time.sleep(min_interval - elapsed)
        self.last_request_time = time.time()
    
    def _request(self, url: str, max_retries: int = 3) -> Optional[dict]:
        """å‘é€HTTPè¯·æ±‚"""
        self._rate_limit()
        
        for attempt in range(max_retries):
            try:
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                return response.json() if response.text else {}
            except Exception as e:
                if attempt < max_retries - 1:
                    time.sleep(2 * (attempt + 1))
                else:
                    logger.debug(f"è¯·æ±‚å¤±è´¥: {url}, {e}")
                    return None
    
    def get_compound_data(self, cid: int) -> Optional[Dict]:
        """è·å–å•ä¸ªåŒ–åˆç‰©çš„å®Œæ•´æ•°æ®"""
        # 1. è·å–åŸºæœ¬å±æ€§
        props_url = f"{self.base_url}/compound/cid/{cid}/property/MolecularFormula,MolecularWeight,CanonicalSMILES,IUPACName,Title/JSON"
        props_data = self._request(props_url)
        
        if not props_data or 'PropertyTable' not in props_data:
            return None
        
        try:
            props = props_data['PropertyTable']['Properties'][0]
        except (KeyError, IndexError):
            return None
        
        # 2. è·å–pKaæ•°æ®
        pka_values = self._extract_pka(cid)
        
        if not pka_values:
            return None
        
        # 3. éªŒè¯SMILES
        smiles = props.get('CanonicalSMILES', '')
        if not smiles or not self._validate_smiles(smiles):
            return None
        
        # 4. æ„å»ºç»“æœ
        compound = {
            'id': f"pubchem_{cid}",
            'cid': cid,
            'smiles': smiles,
            'pka': pka_values[0],  # ä½¿ç”¨ç¬¬ä¸€ä¸ªpKaå€¼
            'compound_name': props.get('Title', ''),
            'molecular_formula': props.get('MolecularFormula', ''),
            'molecular_weight': props.get('MolecularWeight', 0.0),
            'iupac_name': props.get('IUPACName', ''),
            'source': 'PubChem',
            'initial_charge': 0,
            'uhf': 0
        }
        
        return compound
    
    def _extract_pka(self, cid: int) -> List[float]:
        """ä»PubChemè®°å½•ä¸­æå–pKaå€¼"""
        # è·å–å®Œæ•´è®°å½•
        record_url = f"{self.base_url}/compound/cid/{cid}/JSON"
        data = self._request(record_url)
        
        if not data or 'Record' not in data:
            return []
        
        pka_values = []
        
        try:
            record = data['Record']
            sections = record.get('Section', [])
            
            for section in sections:
                pka_values.extend(self._parse_section_for_pka(section))
        except Exception as e:
            logger.debug(f"æå–pKaå¤±è´¥ (CID {cid}): {e}")
        
        return pka_values
    
    def _parse_section_for_pka(self, section: dict) -> List[float]:
        """é€’å½’è§£æsectionä¸­çš„pKaæ•°æ®"""
        pka_values = []
        
        # æ£€æŸ¥æ ‡é¢˜
        heading = section.get('TOCHeading', '').lower()
        if 'pka' in heading or 'dissociation' in heading or 'ionization' in heading:
            # æŸ¥æ‰¾æ•°å€¼
            info_list = section.get('Information', [])
            for info in info_list:
                value = info.get('Value', {})
                if isinstance(value, dict):
                    strings = value.get('StringWithMarkup', [])
                    for string_obj in strings:
                        text = string_obj.get('String', '')
                        # æå–pKaæ•°å€¼
                        matches = re.findall(r'pKa\s*[=:~]?\s*(-?\d+\.?\d*)', text, re.IGNORECASE)
                        for match in matches:
                            try:
                                pka = float(match)
                                if -5 < pka < 20:  # åˆç†èŒƒå›´
                                    pka_values.append(pka)
                            except ValueError:
                                pass
        
        # é€’å½’æ£€æŸ¥å­section
        subsections = section.get('Section', [])
        for subsection in subsections:
            pka_values.extend(self._parse_section_for_pka(subsection))
        
        return pka_values
    
    def _validate_smiles(self, smiles: str) -> bool:
        """éªŒè¯SMILESæœ‰æ•ˆæ€§"""
        try:
            mol = Chem.MolFromSmiles(smiles)
            return mol is not None and mol.GetNumAtoms() > 0
        except:
            return False
    
    def collect(self, target_count: int = 100) -> pd.DataFrame:
        """é‡‡é›†æ•°æ®"""
        logger.info("=" * 60)
        logger.info(f"å¼€å§‹é‡‡é›†æ•°æ®ï¼Œç›®æ ‡: {target_count} ä¸ªåŒ–åˆç‰©")
        logger.info("=" * 60)
        
        results = []
        collected_smiles = set()
        
        # éšæœºæ‰“ä¹±CIDåˆ—è¡¨
        import random
        cids = self.known_pka_cids.copy()
        random.shuffle(cids)
        
        for cid in tqdm(cids, desc="é‡‡é›†è¿›åº¦"):
            if len(results) >= target_count:
                break
            
            compound = self.get_compound_data(cid)
            
            if compound:
                # å»é‡
                if compound['smiles'] not in collected_smiles:
                    results.append(compound)
                    collected_smiles.add(compound['smiles'])
        
        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(results)
        
        # ä¿å­˜
        if len(df) > 0:
            df.to_csv(self.output_file, index=False)
            logger.info(f"\nâœ… æˆåŠŸé‡‡é›† {len(df)} ä¸ªåŒ–åˆç‰©")
            logger.info(f"æ•°æ®å·²ä¿å­˜è‡³: {self.output_file}")
        else:
            logger.warning("æœªé‡‡é›†åˆ°ä»»ä½•æ•°æ®")
        
        return df


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="PubChemæ•°æ®é‡‡é›†å·¥å…·ï¼ˆç®€åŒ–ç‰ˆï¼‰")
    parser.add_argument("--target", type=int, default=100, help="ç›®æ ‡é‡‡é›†æ•°é‡")
    parser.add_argument("--output", type=str, default="data/raw", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    scraper = SimplePubChemScraper(output_dir=args.output)
    df = scraper.collect(target_count=args.target)
    
    if len(df) > 0:
        print("\n" + "=" * 60)
        print("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  æ€»è®¡: {len(df)} ä¸ªåŒ–åˆç‰©")
        print(f"  pKaèŒƒå›´: {df['pka'].min():.2f} - {df['pka'].max():.2f}")
        print(f"  å¹³å‡åˆ†å­é‡: {df['molecular_weight'].mean():.2f}")
        print("=" * 60)


if __name__ == "__main__":
    main()
